{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Pruning in Keras example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEAZYXvZU_XG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN4yVFK5-0Bf",
        "outputId": "241a164a-3025-4c23-93b0-1ed4112940c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 238 kB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJwIonXEVJo6"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psViY5PRDurp"
      },
      "source": [
        "## Train a model for MNIST without pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbY-KGMPvbW9",
        "outputId": "87d001ae-61ac-4558-c48e-43157dc20dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/4\n",
            "1688/1688 [==============================] - 26s 14ms/step - loss: 0.3181 - accuracy: 0.9091 - val_loss: 0.1418 - val_accuracy: 0.9607\n",
            "Epoch 2/4\n",
            "1688/1688 [==============================] - 21s 13ms/step - loss: 0.1299 - accuracy: 0.9628 - val_loss: 0.1033 - val_accuracy: 0.9717\n",
            "Epoch 3/4\n",
            "1688/1688 [==============================] - 22s 13ms/step - loss: 0.0915 - accuracy: 0.9739 - val_loss: 0.0784 - val_accuracy: 0.9780\n",
            "Epoch 4/4\n",
            "1688/1688 [==============================] - 21s 13ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.0637 - val_accuracy: 0.9835\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff16345890>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=4,\n",
        "  validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1qKfXNqo9hk"
      },
      "source": [
        "Evaluate baseline test accuracy and save the model for later usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyIKnbVZafIH",
        "outputId": "472ffd75-1410-4d95-d77a-99560048b2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9782999753952026\n",
            "Saved baseline model to: /tmp/tmp5f6eaeaz.h5\n"
          ]
        }
      ],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', keras_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8747K9OE72P"
      },
      "source": [
        "## Fine-tune pre-trained model with pruning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F19k7ExXF_h2"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq6blGjgFDCW",
        "outputId": "06fe15ee-18e5-4cd2-f1f0-32188694e849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d   (None, 26, 26, 12)       230       \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
            " ling2d (PruneLowMagnitude)                                      \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 2028)             1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dense (  (None, 10)               40572     \n",
            " PruneLowMagnitude)                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDr2ijwpGCI-"
      },
      "source": [
        "### Train and evaluate the model against baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBEn94hXYB1"
      },
      "source": [
        "Fine tune with pruning for two epochs.\n",
        "\n",
        "`tfmot.sparsity.keras.UpdatePruningStep` is required during training, and `tfmot.sparsity.keras.PruningSummaries` provides logs for tracking progress and debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PHDGJryE31X",
        "outputId": "73fdbd12-db3f-4ce4-f605-84d6ced0aa8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "422/422 [==============================] - 18s 36ms/step - loss: 0.0903 - accuracy: 0.9742 - val_loss: 0.0986 - val_accuracy: 0.9760\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.1039 - accuracy: 0.9723 - val_loss: 0.0815 - val_accuracy: 0.9800\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff13691c50>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "  \n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-byC2lYlMkfN"
      },
      "source": [
        "For this example, there is minimal loss in test accuracy after pruning, compared to the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bMFTKSSHyyZ",
        "outputId": "a0ab6602-79b3-4c8b-f553-fb5041917a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9782999753952026\n",
            "Pruned test accuracy: 0.9715999960899353\n"
          ]
        }
      ],
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IepmUPSITn6"
      },
      "source": [
        "## Create 3x smaller models from pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgNP4rbOLH8"
      },
      "source": [
        "Both `tfmot.sparsity.keras.strip_pruning` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression\n",
        "benefits of pruning.\n",
        "\n",
        "*   `strip_pruning` is necessary since it removes every tf.Variable that pruning only needs during training, which would otherwise add to model size during inference\n",
        "*   Applying a standard compression algorithm is necessary since the serialized weight matrices are the same size as they were before pruning. However, pruning makes most of the weights zeros, which is\n",
        "added redundancy that algorithms can utilize to further compress the model.\n",
        "\n",
        "First, create a compressible model for TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7fztWsAOHTz",
        "outputId": "7e24c70f-65f6-4dc3-874d-e596df681483"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpf91tt128.h5\n"
          ]
        }
      ],
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4_bixlrtTbF"
      },
      "source": [
        "Then, create a compressible model for TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIKxSSHmrJSa",
        "outputId": "912859c3-9af0-4cae-fb51-bd41163ab946"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmpzbf24zw5.tflite\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4lv-lRKuMY4"
      },
      "source": [
        "Define a helper function to actually compress the models via gzip and measure the zipped size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E7DXEgUrCDZ"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caxUoJ_BunqU"
      },
      "source": [
        "Compare and see that the models are 3x smaller from pruning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzSXC_nxuqJX",
        "outputId": "7b6464dc-9940-48ae-c06e-ec2eada26e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 78228.00 bytes\n",
            "Size of gzipped pruned Keras model: 25894.00 bytes\n",
            "Size of gzipped pruned TFlite model: 24849.00 bytes\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8D7WnFF5DZR"
      },
      "source": [
        "## Create a 10x smaller model from combining pruning and quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1c2IecBRCdQ"
      },
      "source": [
        "You can apply post-training quantization to the pruned model for additional benefits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy_Lgfh8VkyX",
        "outputId": "6d6eb84a-59af-4c34-c3bf-f0f32680afd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved quantized and pruned TFLite model to: /tmp/tmpurz15e_9.tflite\n",
            "Size of gzipped baseline Keras model: 78228.00 bytes\n",
            "Size of gzipped pruned and quantized TFlite model: 8005.00 bytes\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEYsyYVqNgeY"
      },
      "source": [
        "## See persistence of accuracy from TF to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saadXD4JQsBK"
      },
      "source": [
        "Define a helper function to evaluate the TF Lite model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8yBouuGNqls"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuEFS4CIQvUw"
      },
      "source": [
        "You evaluate the pruned and quantized model and see that the accuracy from TensorFlow persists to the TFLite backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqQTyqz4NsWd",
        "outputId": "083ee4df-b2c4-4fbf-f3cf-9f223be0e5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Pruned and quantized TFLite test_accuracy: 0.9719\n",
            "Pruned TF test accuracy: 0.9715999960899353\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jCQe3FjxLau",
        "outputId": "96ad9898-3b6b-416a-c3b2-05f49163d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/4\n",
            "1688/1688 [==============================] - 74s 44ms/step - loss: 0.2265 - accuracy: 0.9305 - val_loss: 0.0657 - val_accuracy: 0.9838\n",
            "Epoch 2/4\n",
            "1688/1688 [==============================] - 70s 41ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 0.0587 - val_accuracy: 0.9855\n",
            "Epoch 3/4\n",
            "1688/1688 [==============================] - 69s 41ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 0.0556 - val_accuracy: 0.9843\n",
            "Epoch 4/4\n",
            "1688/1688 [==============================] - 72s 43ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.0587 - val_accuracy: 0.9832\n",
            "Baseline test accuracy: 0.9836999773979187\n",
            "Saved baseline model to: /tmp/tmpx0oqwd8p.h5\n"
          ]
        }
      ],
      "source": [
        "fashion = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(trainX, trainy), (testX, testy) = fashion\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=4,\n",
        "  validation_split=0.1,\n",
        ")\n",
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', keras_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G7tS5XPCjVu",
        "outputId": "7ea55bcf-c6fa-4b48-e4ad-85269a2ff91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 26, 26, 12)       230       \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 24, 24, 12)       2606      \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 22, 22, 12)       2606      \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 11, 11, 12)       1         \n",
            " ling2d_1 (PruneLowMagnitude                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 1452)             1         \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_1  (None, 10)               29052     \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_2  (None, 10)               212       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_3  (None, 10)               212       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,921\n",
            "Trainable params: 17,486\n",
            "Non-trainable params: 17,435\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwX5rrFmCjVx",
        "outputId": "5f4bca64-8bfc-4bbd-cd7a-23e451fa7871"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmp4y366m80.h5\n"
          ]
        }
      ],
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2yFtD_ICjVz",
        "outputId": "43ed0f5d-2804-4901-e884-d234d493c1dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmpwv0fd3pz.tflite\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty1TNdECCjV1",
        "outputId": "b2dc9877-1777-4102-b18e-9f1165792309"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved quantized and pruned TFLite model to: /tmp/tmp3flvvqxq.tflite\n",
            "Size of gzipped baseline Keras model: 68307.00 bytes\n",
            "Size of gzipped pruned and quantized TFlite model: 18519.00 bytes\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxk5moc9CjV2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpSLZjWtCjV3",
        "outputId": "70c7f604-b98d-414c-bdc3-0621dc86f0e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Pruned and quantized TFLite test_accuracy: 0.9835\n",
            "Pruned TF test accuracy: 0.9715999960899353\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uz12aB4CjV4",
        "outputId": "12255522-a763-417e-c0e5-e870933ef082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "422/422 [==============================] - 66s 147ms/step - loss: 0.1171 - accuracy: 0.9637 - val_loss: 0.1235 - val_accuracy: 0.9645\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 60s 141ms/step - loss: 0.1078 - accuracy: 0.9674 - val_loss: 0.0718 - val_accuracy: 0.9802\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff15ddbbd0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "  \n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA1RQtheCjV6"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16;\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl1OGk38v1Z2",
        "outputId": "23c42eba-8cdc-4af0-c547-522da7357ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX.shape, testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdqnOd_wCjV8",
        "outputId": "daf9b696-ab01-41dc-e3af-f5fc446274da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 84), (10000, 28, 84))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX=np.dstack([trainX] * 3)\n",
        "testX=np.dstack([testX]*3)\n",
        "trainX.shape,testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmfvumAOCjV9",
        "outputId": "38f1cbf8-bf4b-464d-ada1-b79846382e24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reshape images as per the tensor format required by tensorflow\n",
        "train_X = trainX.reshape(-1, 28,28,3)\n",
        "test_X= testX.reshape (-1,28,28,3)\n",
        "train_X.shape,test_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2uxlw5ACjV-",
        "outputId": "21187b36-0068-439b-8696-5ad233fd8ebf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "train_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in train_X])\n",
        "test_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in test_X])\n",
        "#train_x = preprocess_input(x)\n",
        "train_X.shape, test_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBPX0458CjV_"
      },
      "outputs": [],
      "source": [
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255.\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT0_JBjgCjWB"
      },
      "outputs": [],
      "source": [
        "train_Y_one_hot = to_categorical(trainy)\n",
        "test_Y_one_hot = to_categorical(testy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swsXa7lkCjWD"
      },
      "outputs": [],
      "source": [
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X,\n",
        "                                                           train_Y_one_hot,\n",
        "                                                           test_size=0.2,\n",
        "                                                           random_state=13\n",
        "                                                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRFV2dWCCjWF",
        "outputId": "973a7ade-4f6b-42b0-8ebc-4b5efe299b72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((48000, 48, 48, 3), (12000, 48, 48, 3), (48000, 10), (12000, 10))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq23A5EICjWG"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 48\n",
        "IMG_HEIGHT = 48\n",
        "IMG_DEPTH = 3\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk_I8JEpCjWH"
      },
      "outputs": [],
      "source": [
        "train_X = preprocess_input(train_X)\n",
        "valid_X = preprocess_input(valid_X)\n",
        "test_X  = preprocess_input (test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R0Br9jICjWH",
        "outputId": "71fee018-bcfa-4f15-8239-68926fd58025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False, \n",
        "                  input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
        "                 )\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "COKHgEELCjWI",
        "outputId": "41f1ab2c-639a-4491-9854-2749eb54d87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 1225s 408ms/step\n",
            "625/625 [==============================] - 251s 402ms/step\n"
          ]
        }
      ],
      "source": [
        "train_features = conv_base.predict(np.array(train_X), batch_size=BATCH_SIZE, verbose=1)\n",
        "test_features = conv_base.predict(np.array(test_X), batch_size=BATCH_SIZE, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SIf0a_RtCjWJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
